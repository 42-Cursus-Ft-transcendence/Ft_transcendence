input {
  tcp {
    port => 5044
    ssl_enable => true
    ssl_cert => "/usr/share/logstash/certs/logstash.crt"
    ssl_key => "/usr/share/logstash/certs/logstash.key"
  }
  # 필요에 따라 파일 입력도 추가할 수 있습니다.
  # file {
  #   path => "/var/log/fastify/*.log"
  #   start_position => "beginning"
  # }
}

filter {
  # 로그 메시지가 JSON 형태인 경우 파싱
  json {
    source => "message"
    target => "parsed_json"
    remove_field => ["message"]
  }

  # Grok 필터를 이용하여 로그 패턴 파싱 (예시)
  grok {
    match => { "parsed_json.log" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:level} %{GREEDYDATA:msg}" }
    break_on_match => false
  }

  # 날짜 필터로 타임스탬프 필드를 표준 날짜 형식으로 변환
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # 메타데이터 추가: 환경, 서비스 이름 등
  mutate {
    add_field => {
      "environment" => "development"
      "service" => "ft_transcende"
    }
  }

  # Useragent 필터: User-Agent 문자열 분석 (필드 이름이 'agent'라고 가정)
  useragent {
    source => "agent"
    target => "user_agent"
  }

  # Fingerprint 필터: 고유 식별자 생성
  fingerprint {
    source => ["host", "message"]
    target => "[@metadata][fingerprint]"
    method => "SHA1"
  }
}

output {
  stdout { codec => rubydebug }
  elasticsearch {
    hosts => ["https://elasticsearch:9200"]
    index => "ft_transcende-logs-%{+YYYY.MM.dd}"
    data_stream => false 
    timeout => 90
    healthcheck_interval => 15

    user => "logstash_system"
    password => "${LOGSTASH_SYSTEM_PASSWORD}"
    ssl_enabled => true
    cacert => "/usr/share/logstash/ca/ca.crt"
    ssl_certificate_verification => true 
    ssl_verification_mode => "full"
    # ssl_certificate_verification => false  # for debug only, not recommended

    retry_initial_interval => 5   # 최초 재시도 간격 (초)
    retry_max_interval => 60      # 최대 재시도 간격 (초)
    resurrect_delay => 15000
    pool_max => 1000              # 연결 풀 최대 개수
    pool_max_per_route => 100     # 각 호스트당 최대 연결 수

    manage_template => true
    template_name => "ecs-logstash"
    template_overwrite => true
  }
}